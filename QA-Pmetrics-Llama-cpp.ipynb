{
 "cells": [
  {
   "attachments": {
    "3dce65bf-ad2d-4d56-8dca-80fcd28c0349.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3bca21f7-800f-46aa-aab9-9ee520a90469",
   "metadata": {},
   "source": [
    "![1_mdzyMcDhL0YLtgtfw7eaaA.webp](attachment:3dce65bf-ad2d-4d56-8dca-80fcd28c0349.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d688950-984e-472e-8e9f-f39f9435d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU transformers accelerate einops langchain xformers bitsandbytes faiss-gpu sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b407ef76-e854-415e-a5f2-9744a181e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb38a7a-0832-49fd-bd80-d40f3226a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/entityjy/src/AITextGeneration/llama2/llama-2-7b-chat.Q4_0.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.56 GiB (4.54 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.22 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  3577.56 MiB, ( 3577.62 /  5461.34)\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
      "llm_load_tensors:      Metal buffer size =  3577.56 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7  (1007)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =  1024.00 MiB, ( 4603.19 /  5461.34)\n",
      "llama_kv_cache_init:      Metal KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 4603.20 /  5461.34)\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   172.02 MiB, ( 4775.20 /  5461.34)\n",
      "llama_new_context_with_model: graph splits (measure): 3\n",
      "llama_new_context_with_model:      Metal compute buffer size =   172.00 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    12.00 MiB\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '2', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'LLaMA v2'}\n"
     ]
    }
   ],
   "source": [
    "# /Users/entityjy/llama2/llama.cpp/models/llama-2-7b-chat.ggmlv3.q4_K_M.gguf.bin\n",
    "\n",
    "model = langchain.LlamaCpp(\n",
    "    model_path=\"/Users/entityjy/src/AITextGeneration/llama2/llama-2-7b-chat.Q4_0.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_batch=512,\n",
    "    n_ctx=2048,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    verbose=True,\n",
    "    repeat_penalty=1.1,\n",
    "    temperature=0.3,\n",
    "    max_tokens=256,\n",
    "    # stop=['\\nHuman:', '\\n```\\n', '\\n\\n\\n']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113cc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cff4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/entityjy/src/AITextGeneration/QA-Pmetrics/TestData/\"\n",
    "file_names = [\"data.Rmd\", \"intro.Rmd\", \"models.Rmd\", \"objects.Rmd\", \"overview.Rmd\", \"plotly.Rmd\", \"pmetrics.Rmd\", \"pta.Rmd\", \"running.Rmd\", \"simulation.Rmd\", \"workflow.Rmd\"]\n",
    "documents = []\n",
    "for name in file_names:\n",
    "    loader = UnstructuredMarkdownLoader(root + name)\n",
    "    documents.append(loader.load().pop())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff5032ca-dd9a-4c6c-bb2c-8b40c3dd34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ff2ffd-f5e8-4c23-b63f-815008ff673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"mps\"}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "# storing embeddings in the vector store\n",
    "vectorstore = FAISS.from_documents(all_splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3e83b4-1ab0-4c28-ada3-a28c3df8a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant that answers the question given by the user based on the question and prior chat history.\n",
    "If the question cannot be answered with the given documents, answer with, \"I do not know.\"\n",
    "Chat History: {chat_history}\n",
    "Question: {question}\n",
    "Answer: \"\"\"\n",
    "promptTemplate = PromptTemplate(\n",
    "    input_variables=[\"question\", \"chat_history\"],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\", return_messages=True)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(model, vectorstore.as_retriever(), return_source_documents=False, condense_question_prompt=promptTemplate, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb9c1cc-36fc-4a8d-8601-bb0478259928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "That's it!\n",
      "\n",
      "How do I get help?\n",
      "\n",
      "Head on over to our Discussion board at Github.\n",
      "\n",
      "How do I start using Pmetrics?\n",
      "\n",
      "A good place to start is to run PM_tutorial(), which will install an Examples folder at your chosen location, which will contain sample data, models, and a script to get you started building and simulating from population models. Also have a look at the Articles on this website. All functions are extensively documented, most with examples, which can be seen in the Reference section of the website. There are also more tutorials and references on our Laboratory of Applied Pharmacokinetics and Bioinformatics website.\n",
      "\n",
      "Thank you for your support!\n",
      "\n",
      "Rscript contains a skeleton R script to begin Pmetrics runs in the new project.\n",
      "\n",
      "Runs should contain all files required for a run (described next) and it will also contain the resulting numerically ordered run directories created after each Pmetrics NPAG or IT2B run.\n",
      "\n",
      "Sim can contain any files related to simulations\n",
      "\n",
      "src is a repository for original and manipulated source data files\n",
      "\n",
      "You are free to edit this directory tree structure as you please, or make your\n",
      "own entirely.\n",
      "\n",
      "Getting the required inputs to run Pmetrics\n",
      "\n",
      "R6\n",
      "\n",
      "There is a full tutorial encoded inside Pmetrics to teach new users the basic functionality of the whole package. To start that tutorial in R type:\n",
      "{r echo=T, eval=F}\n",
      "library(Pmetrics)\n",
      "PM_tutorial()\n",
      "Follow the instructions prompted in the terminal.\n",
      "\n",
      "Model List\n",
      "\n",
      "You can write a Pmetrics model list in R. Blocks in the model files which \n",
      "were delimited with the \"#\" character become lists in R6. \n",
      "You can also generate a model in the app and copy it as a list to R which can be\n",
      "used in PM_model$new(copied_list). Once in R, PM_model list objects can \n",
      "be updated using the $update() method.\n",
      "\n",
      "Model Files\n",
      "\n",
      "The format of the .txt model file has been unchanged since Pmetrics 0.4. You can \n",
      "write the file by hand, or use the app to create a model and then save it to a file.\n",
      "Once you have a file, it can be loaded in to R with PM_model$new(\"file\").\n",
      "\n",
      "```{r echo = T, eval = F}\n",
      "mod1 <- PM_model$new(\"model.txt\")\n",
      "\n",
      "assumes model.txt is in working directory\n",
      "\n",
      "check with list.files() and/or getwd()\n",
      "\n",
      "```\n",
      "\n",
      "You can also type PMmanual() to launch this website from within Pmetrics.\n",
      "\n",
      "Pmetrics will check for updates automatically every time you load it\n",
      "with library(Pmetrics) and you are connected to the internet. \n",
      "If an update is available, it will provide a\n",
      "brief message to inform you. You can then reinstall the package from github.\n",
      "\n",
      "Customizing Options\n",
      "\n",
      "You can change global options in Pmetrics with \n",
      "setPMoptions(). The getPMoptions() function will return the \n",
      "current options.\n",
      "\n",
      "Question: How do I learn Pmetrics?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " To learn Pmetrics, you can start by reading the documentation and tutorials provided on the website. You can also use the Discussion board at Github to ask questions and get help from other users. Additionally, you can run the PM_tutorial() function in R to learn the basic functionality of the package.\n",
      "[HumanMessage(content='How do I learn Pmetrics?'), AIMessage(content=' To learn Pmetrics, you can start by reading the documentation and tutorials provided on the website. You can also use the Discussion board at Github to ask questions and get help from other users. Additionally, you can run the PM_tutorial() function in R to learn the basic functionality of the package.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18176.94 ms\n",
      "llama_print_timings:      sample time =     145.17 ms /    65 runs   (    2.23 ms per token,   447.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20766.75 ms /   760 tokens (   27.32 ms per token,    36.60 tokens per second)\n",
      "llama_print_timings:        eval time =    7813.81 ms /    64 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
      "llama_print_timings:       total time =   33928.47 ms /   824 tokens\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "query = \"How do I learn Pmetrics?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "print(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff6b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI assistant that answers the question given by the user based on the question and prior chat history.\n",
      "If the question cannot be answered with the given documents, answer with, \"I do not know.\"\n",
      "Chat History: \n",
      "Human: How do I learn Pmetrics?\n",
      "Assistant:  To learn Pmetrics, you can start by reading the documentation and tutorials provided on the website. You can also use the Discussion board at Github to ask questions and get help from other users. Additionally, you can run the PM_tutorial() function in R to learn the basic functionality of the package.\n",
      "Question: Where can I find that tutorial?\n",
      "Answer: \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18176.94 ms\n",
      "llama_print_timings:      sample time =      75.28 ms /    42 runs   (    1.79 ms per token,   557.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2426.33 ms /   145 tokens (   16.73 ms per token,    59.76 tokens per second)\n",
      "llama_print_timings:        eval time =    4565.49 ms /    41 runs   (  111.35 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =   10342.55 ms /   186 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "That's it!\n",
      "\n",
      "How do I get help?\n",
      "\n",
      "Head on over to our Discussion board at Github.\n",
      "\n",
      "How do I start using Pmetrics?\n",
      "\n",
      "A good place to start is to run PM_tutorial(), which will install an Examples folder at your chosen location, which will contain sample data, models, and a script to get you started building and simulating from population models. Also have a look at the Articles on this website. All functions are extensively documented, most with examples, which can be seen in the Reference section of the website. There are also more tutorials and references on our Laboratory of Applied Pharmacokinetics and Bioinformatics website.\n",
      "\n",
      "Thank you for your support!\n",
      "\n",
      "Rscript contains a skeleton R script to begin Pmetrics runs in the new project.\n",
      "\n",
      "Runs should contain all files required for a run (described next) and it will also contain the resulting numerically ordered run directories created after each Pmetrics NPAG or IT2B run.\n",
      "\n",
      "Sim can contain any files related to simulations\n",
      "\n",
      "src is a repository for original and manipulated source data files\n",
      "\n",
      "You are free to edit this directory tree structure as you please, or make your\n",
      "own entirely.\n",
      "\n",
      "Getting the required inputs to run Pmetrics\n",
      "\n",
      "R6\n",
      "\n",
      "There is a full tutorial encoded inside Pmetrics to teach new users the basic functionality of the whole package. To start that tutorial in R type:\n",
      "{r echo=T, eval=F}\n",
      "library(Pmetrics)\n",
      "PM_tutorial()\n",
      "Follow the instructions prompted in the terminal.\n",
      "\n",
      "You can also type PMmanual() to launch this website from within Pmetrics.\n",
      "\n",
      "Pmetrics will check for updates automatically every time you load it\n",
      "with library(Pmetrics) and you are connected to the internet. \n",
      "If an update is available, it will provide a\n",
      "brief message to inform you. You can then reinstall the package from github.\n",
      "\n",
      "Customizing Options\n",
      "\n",
      "You can change global options in Pmetrics with \n",
      "setPMoptions(). The getPMoptions() function will return the \n",
      "current options.\n",
      "\n",
      "Model List\n",
      "\n",
      "You can write a Pmetrics model list in R. Blocks in the model files which \n",
      "were delimited with the \"#\" character become lists in R6. \n",
      "You can also generate a model in the app and copy it as a list to R which can be\n",
      "used in PM_model$new(copied_list). Once in R, PM_model list objects can \n",
      "be updated using the $update() method.\n",
      "\n",
      "Model Files\n",
      "\n",
      "The format of the .txt model file has been unchanged since Pmetrics 0.4. You can \n",
      "write the file by hand, or use the app to create a model and then save it to a file.\n",
      "Once you have a file, it can be loaded in to R with PM_model$new(\"file\").\n",
      "\n",
      "```{r echo = T, eval = F}\n",
      "mod1 <- PM_model$new(\"model.txt\")\n",
      "\n",
      "assumes model.txt is in working directory\n",
      "\n",
      "check with list.files() and/or getwd()\n",
      "\n",
      "```\n",
      "\n",
      "Question:  The tutorial can be found on the Pmetrics website under the \"Documentation\" section. You can also search for it on Google or other search engines by using the keywords \"Pmetrics tutorial\".\n",
      "Helpful Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhere can I find that tutorial?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(memory\u001b[38;5;241m.\u001b[39mchat_memory\u001b[38;5;241m.\u001b[39mmessages)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    361\u001b[0m }\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    166\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    151\u001b[0m     inputs,\n\u001b[1;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/conversational_retrieval/base.py:166\u001b[0m, in \u001b[0;36mBaseConversationalRetrievalChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    164\u001b[0m         new_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m new_question\n\u001b[1;32m    165\u001b[0m     new_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m chat_history_str\n\u001b[0;32m--> 166\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_inputs\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     output[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m answer\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:543\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    539\u001b[0m         _output_key\n\u001b[1;32m    540\u001b[0m     ]\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    544\u001b[0m         _output_key\n\u001b[1;32m    545\u001b[0m     ]\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    361\u001b[0m }\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    166\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    151\u001b[0m     inputs,\n\u001b[1;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:136\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    135\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 136\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:244\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:293\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:363\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    361\u001b[0m }\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:162\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    163\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    164\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    165\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    166\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    150\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    151\u001b[0m     inputs,\n\u001b[1;32m    152\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    100\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 103\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/language_models/llms.py:525\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    519\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    523\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    524\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/language_models/llms.py:698\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         )\n\u001b[1;32m    685\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    686\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    687\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m     ]\n\u001b[0;32m--> 698\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/language_models/llms.py:562\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    561\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    563\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/language_models/llms.py:549\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    541\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 549\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    557\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1134\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1131\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1133\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1137\u001b[0m     )\n\u001b[1;32m   1138\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:291\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    292\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    293\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    294\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    296\u001b[0m     ):\n\u001b[1;32m    297\u001b[0m         combined_text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:344\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    343\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    345\u001b[0m     logprobs \u001b[38;5;241m=\u001b[39m part[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    346\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[1;32m    347\u001b[0m         text\u001b[38;5;241m=\u001b[39mpart[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    348\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs},\n\u001b[1;32m    349\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/llama_cpp/llama.py:850\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m    848\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 850\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    851\u001b[0m     prompt_tokens,\n\u001b[1;32m    852\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    853\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m    854\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[1;32m    855\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[1;32m    856\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m    857\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[1;32m    858\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[1;32m    859\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[1;32m    860\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[1;32m    861\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[1;32m    862\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[1;32m    863\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[1;32m    864\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[1;32m    865\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m    866\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m    867\u001b[0m ):\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_eos:\n\u001b[1;32m    869\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetokenize(completion_tokens)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/llama_cpp/llama.py:624\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    626\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    627\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m         penalize_nl\u001b[38;5;241m=\u001b[39mpenalize_nl,\n\u001b[1;32m    641\u001b[0m     )\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stopping_criteria \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m stopping_criteria(\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_ids, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scores[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m    644\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/llama_cpp/llama.py:437\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    433\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    435\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    436\u001b[0m )\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/llama_cpp/_internals.py:309\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/langchain/lib/python3.10/site-packages/llama_cpp/llama_cpp.py:1593\u001b[0m, in \u001b[0;36mllama_decode\u001b[0;34m(ctx, batch)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllama_decode\u001b[39m(ctx: llama_context_p, batch: llama_batch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Positive return values does not mean a fatal error, but rather a warning.\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;124;03m    0 - success\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;124;03m    1 - could not find a KV slot for the batch (try reducing the size of the batch or increase the context)\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m    < 0 - error\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query = \"Where can I find that tutorial?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])\n",
    "print(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60babb7d-12d3-4194-b273-b496f9315695",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "while True:\n",
    "    print(\"Enter prompt\")\n",
    "    Input = input()\n",
    "    if Input == \"quit\":\n",
    "        break\n",
    "    query = Input\n",
    "    result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "    print(result['answer'])\n",
    "    print(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65e5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
